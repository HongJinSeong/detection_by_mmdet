{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02c548a5-f62b-489b-b909-ebe765759095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "\n",
    "\n",
    "import copy\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "\n",
    "from mmdet.apis import set_random_seed\n",
    "\n",
    "import glob as _glob\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c7656b-f874-4434-8c9b-f56b3fa116f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glob(dir, pats, recursive=False):  # faster than match, python3 only\n",
    "    pats = pats if isinstance(pats, (list, tuple)) else [pats]\n",
    "    matches = []\n",
    "    for pat in pats:\n",
    "        matches += _glob.glob(os.path.join(dir, pat), recursive=recursive)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dda1ebd-c97e-4f21-b8f5-8e7a942b13bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 추가수정 기존 받았던 pretrain과 매칭되는 config로 수정 \n",
    "cfg = Config.fromfile('mmdetection/configs/yolof/yolof_r50_c5_8x8_1x_coco.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23572400-c55a-47c1-8708-e190011020ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@DATASETS.register_module()\n",
    "class Auto_drive_dataset(CustomDataset):\n",
    "    CLASSES=('car','pedestrian','traffic sign', 'motorcycle', 'bus','truck','bicycle','traffic light','special vehicle', 'non')\n",
    "\n",
    "\n",
    "    def load_annotations(self, ann_file):\n",
    "        \n",
    "        CLASSES_dict = {'car' : 0 , 'pedestrian':1, 'traffic sign':2, 'motorcycle':3, 'bus':4,'truck':5 ,'bicycle':6 ,'traffic light':7,'special vehicle':8,'non':9}\n",
    "        \n",
    "        cat2label = {k: i for i, k in enumerate(self.CLASSES)}\n",
    "        # load image list from file\n",
    "        image_list = mmcv.list_from_file(self.ann_file)\n",
    "        \n",
    "        data_infos = []\n",
    "        \n",
    "        for idx,img in enumerate(image_list):\n",
    "            json_data = {}\n",
    "            with open(img, \"r\") as json_file:\n",
    "                json_data = json.load(json_file)\n",
    "            # 수정 prefix 제대로 적용안되서 문자열 그대로 입력 \n",
    "            filename = '2D_BB'+'/'+json_data['Source_Image_Info']['Img_path'][0:9]+'/'+json_data['Source_Image_Info']['Img_path']+'/'+json_data['Source_Image_Info']['Img_name']\n",
    "\n",
    "            height, width = json_data['Source_Image_Info']['Resolution']\n",
    "\n",
    "            data_info = dict(filename=filename, width=width, height=height)\n",
    "\n",
    "            gt_bboxes = []\n",
    "            gt_labels = []\n",
    "\n",
    "            for idx in range(len(json_data['Annotation'])):\n",
    "                gt_labels.append(CLASSES_dict[json_data['Annotation'][idx]['Label']])\n",
    "                gt_bboxes.append(json_data['Annotation'][idx]['Coordinate'])\n",
    "\n",
    "\n",
    "            data_anno = dict(\n",
    "                    bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
    "                    labels=np.array(gt_labels, dtype=np.long))\n",
    "\n",
    "\n",
    "            data_info.update(ann=data_anno)\n",
    "            data_infos.append(data_info)\n",
    "            \n",
    "            if idx!=0 and idx%20000==0:\n",
    "                print(str(idx)+'/'+str(image_list)+' load annotations END!')\n",
    "            \n",
    "        \n",
    "        \n",
    "        return data_infos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb024a9-61a0-41a1-82eb-c7b3f55463ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "dataset_type = 'Auto_drive_dataset'\n",
      "data_root = ''\n",
      "img_norm_cfg = dict(\n",
      "    mean=[103.53, 116.28, 123.675], std=[1.0, 1.0, 1.0], to_rgb=False)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(type='LoadAnnotations', with_bbox=True),\n",
      "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(type='RandomShift', shift_ratio=0.5, max_shift_px=32),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[103.53, 116.28, 123.675],\n",
      "        std=[1.0, 1.0, 1.0],\n",
      "        to_rgb=False),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(384, 384),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(type='Pad', size=(384, 384), pad_val=114.0),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[103.53, 116.28, 123.675],\n",
      "                std=[1.0, 1.0, 1.0],\n",
      "                to_rgb=False),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=8,\n",
      "    workers_per_gpu=8,\n",
      "    train=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/coco/annotations/instances_train2017.json',\n",
      "        img_prefix='data/coco/train2017/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(type='LoadAnnotations', with_bbox=True),\n",
      "            dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(type='RandomShift', shift_ratio=0.5, max_shift_px=32),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[103.53, 116.28, 123.675],\n",
      "                std=[1.0, 1.0, 1.0],\n",
      "                to_rgb=False),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ]),\n",
      "    val=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/coco/annotations/instances_val2017.json',\n",
      "        img_prefix='data/coco/val2017/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(1333, 800),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]),\n",
      "    test=dict(\n",
      "        type='CocoDataset',\n",
      "        ann_file='data/coco/annotations/instances_val2017.json',\n",
      "        img_prefix='data/coco/val2017/',\n",
      "        pipeline=[\n",
      "            dict(type='LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(384, 384),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(type='Pad', size=(384, 384), pad_val=114.0),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[103.53, 116.28, 123.675],\n",
      "                        std=[1.0, 1.0, 1.0],\n",
      "                        to_rgb=False),\n",
      "                    dict(type='DefaultFormatBundle'),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ]))\n",
      "evaluation = dict(interval=1, metric='bbox')\n",
      "optimizer = dict(\n",
      "    type='SGD',\n",
      "    lr=0.12,\n",
      "    momentum=0.9,\n",
      "    weight_decay=0.0001,\n",
      "    paramwise_cfg=dict(\n",
      "        norm_decay_mult=0.0,\n",
      "        custom_keys=dict(backbone=dict(lr_mult=0.3333333333333333))))\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=1500,\n",
      "    warmup_ratio=0.00066667,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "model = dict(\n",
      "    type='YOLOF',\n",
      "    backbone=dict(\n",
      "        type='ResNet',\n",
      "        depth=50,\n",
      "        num_stages=4,\n",
      "        out_indices=(3, ),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=False),\n",
      "        norm_eval=True,\n",
      "        style='caffe',\n",
      "        init_cfg=dict(\n",
      "            type='Pretrained',\n",
      "            checkpoint='open-mmlab://detectron/resnet50_caffe')),\n",
      "    neck=dict(\n",
      "        type='DilatedEncoder',\n",
      "        in_channels=2048,\n",
      "        out_channels=512,\n",
      "        block_mid_channels=128,\n",
      "        num_residual_blocks=4),\n",
      "    bbox_head=dict(\n",
      "        type='YOLOFHead',\n",
      "        num_classes=10,\n",
      "        in_channels=512,\n",
      "        reg_decoded_bbox=True,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            ratios=[1.0],\n",
      "            scales=[1, 2, 4, 8, 16],\n",
      "            strides=[32]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0],\n",
      "            add_ctr_clamp=True,\n",
      "            ctr_clamp=32),\n",
      "        loss_cls=dict(\n",
      "            type='FocalLoss',\n",
      "            use_sigmoid=True,\n",
      "            gamma=2.0,\n",
      "            alpha=0.25,\n",
      "            loss_weight=1.0),\n",
      "        loss_bbox=dict(type='GIoULoss', loss_weight=1.0)),\n",
      "    train_cfg=dict(\n",
      "        assigner=dict(\n",
      "            type='UniformAssigner', pos_ignore_thr=0.15, neg_ignore_thr=0.7),\n",
      "        allowed_border=-1,\n",
      "        pos_weight=-1,\n",
      "        debug=False),\n",
      "    test_cfg=dict(\n",
      "        nms_pre=1000,\n",
      "        min_bbox_size=0,\n",
      "        score_thr=0.05,\n",
      "        nms=dict(type='nms', iou_threshold=0.6),\n",
      "        max_per_img=100))\n",
      "img_scale = (384, 384)\n",
      "seed = 0\n",
      "gpu_ids = range(0, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg.dataset_type  = 'Auto_drive_dataset'\n",
    "cfg.data_root = ''\n",
    "cfg.img_scale = (384, 384)\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=cfg.img_scale,\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Pad', size=cfg.img_scale, pad_val=114.0),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='DefaultFormatBundle'),\n",
    "            dict(type='Collect', keys=['img'])\n",
    "        ])\n",
    "]\n",
    "\n",
    "\n",
    "#추가수정 ( default class 80개라서 에러발생)\n",
    "cfg.model.bbox_head.num_classes=10\n",
    "\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "\n",
    "# Set seed to facitate reproducing the result\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "print(f'Config:\\n{cfg.pretty_text}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "611891e1-2846-463b-bc98-b9b6ab8c2316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: checkpoints/epoch_4.pth\n"
     ]
    }
   ],
   "source": [
    "# Build the detector\n",
    "#model = init_detector(config, checkpoint, device='cuda:0')\n",
    "checkpoint='checkpoints/epoch_4.pth'\n",
    "model = init_detector(cfg,checkpoint, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53d185ca-bab7-45b0-9c6a-c2ad163789ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/9519 END!\n",
      "1000/9519 END!\n",
      "2000/9519 END!\n",
      "3000/9519 END!\n",
      "4000/9519 END!\n",
      "5000/9519 END!\n",
      "6000/9519 END!\n",
      "7000/9519 END!\n",
      "8000/9519 END!\n",
      "9000/9519 END!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from mmdet.core.bbox import BboxOverlaps2D\n",
    "\n",
    "\n",
    "def IoU(box1, box2):\n",
    "    # box = (x1, y1, x2, y2)\n",
    "    box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n",
    "    box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n",
    "\n",
    "    # obtain x1, y1, x2, y2 of the intersection\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "\n",
    "    # compute the width and height of the intersection\n",
    "    w = max(0, x2 - x1 + 1)\n",
    "    h = max(0, y2 - y1 + 1)\n",
    "\n",
    "    inter = w * h\n",
    "    iou = inter / (box1_area + box2_area - inter)\n",
    "    return iou\n",
    "\n",
    "# valdiation 대상 목록 load\n",
    "ls=mmcv.list_from_file('splits/val.txt')\n",
    "\n",
    "CLASSES_dict = {0:'car'  , 1:'pedestrian', 2:'traffic sign', 3:'motorcycle', 4:'bus',5:'truck' ,6:'bicycle' ,7:'traffic light',8:'special vehicle',9:'non'}\n",
    "\n",
    "anno_data = {}\n",
    "\n",
    "\n",
    "########################################\n",
    "# mAP 계산 대상 txt파일로 생성 \n",
    "######################################\n",
    "\n",
    "# IOU 측정용 데이터 생성 part\n",
    "# 저장된 output 양식의 클래스명에 ' '가 있으면 안되서 ' '는 '_' 로 수정\n",
    "for idx, data in enumerate(ls):\n",
    "    json_data = {}\n",
    "    with open(data, \"r\") as json_file:\n",
    "        json_data = json.load(json_file)\n",
    "    \n",
    "    imgpath='2D_BB/'+json_data['Source_Image_Info']['Img_path'][0:9]+'/'+json_data['Source_Image_Info']['Img_path']+'/'+json_data['Source_Image_Info']['Img_name']\n",
    "    \n",
    "    gt_bboxes = []\n",
    "    gt_labels = []\n",
    "\n",
    "    results = inference_detector(model, imgpath)\n",
    "    \n",
    "    #eval_map(result,anno_data)\n",
    "    f = open(\"output_for_val/detection_result/\"+json_data['Source_Image_Info']['Img_name'][0:-4]+'.txt','a')\n",
    "    \n",
    "    # 예측값 write\n",
    "    for iidx, result in enumerate(results):\n",
    "        for wr_t in result:\n",
    "                f.write(CLASSES_dict[iidx].replace(' ','_')+' '+str(wr_t[4])+' '+str(wr_t[0])+' '+str(wr_t[1])+' '+str(wr_t[2])+' '+str(wr_t[3])+'\\n')\n",
    "\n",
    "    f.close()\n",
    "    \n",
    "    f = open(\"output_for_val/ground_truth/\"+json_data['Source_Image_Info']['Img_name'][0:-4]+'.txt','a')\n",
    "    \n",
    "    # grundtruth write\n",
    "    for anno in json_data['Annotation']:\n",
    "        f.write(anno['Label'].replace(' ','_')+' '+str(anno['Coordinate'][0])+' '+str(anno['Coordinate'][1])+' '+str(anno['Coordinate'][2])+' '+str(anno['Coordinate'][3])+'\\n')\n",
    "    f.close()\n",
    "    \n",
    "    if idx%1000==0:\n",
    "        print( str(idx)+'/'+str(len(ls))+' END!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a012a8df-f0ba-4700-9b1c-f871f4ee4921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/output_for_val/detection_result\n",
      "/root/output_for_val/ground_truth\n",
      "20.87% = bicycle AP \n",
      "mAP/main.py:721: MatplotlibDeprecationWarning: \n",
      "The set_window_title function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use manager.set_window_title or GUI-specific methods instead.\n",
      "38.40% = bus AP \n",
      "34.32% = car AP \n",
      "4.75% = motorcycle AP \n",
      "1.04% = non AP \n",
      "11.19% = pedestrian AP \n",
      "38.86% = special_vehicle AP \n",
      "1.14% = traffic_light AP \n",
      "8.64% = traffic_sign AP \n",
      "36.21% = truck AP \n",
      "mAP = 19.54%\n",
      "mAP/main.py:314: MatplotlibDeprecationWarning: \n",
      "The set_window_title function was deprecated in Matplotlib 3.4 and will be removed two minor releases later. Use manager.set_window_title or GUI-specific methods instead.\n",
      "Figure(640x480)\n"
     ]
    }
   ],
   "source": [
    "#  https://github.com/Cartucho/mAP/ 소스 사용 \n",
    "#  default로 IOU_threshold값 0.5로 되어있음 \n",
    "#  위에서 저장한 outpput text file과 groundtruth text file 기준으로 처리 \n",
    "!python mAP/main.py --detection_path=/root/output_for_val/detection_result --groundtruth_path=/root/output_for_val/ground_truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b99739e-0dd3-49b4-8ee7-87367aa7ce79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c051129-8aa2-400b-8706-2ae526180d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
