{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53989674-3f26-46a2-be85-6e16ac8437b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### mmdetection에 필요한 좌표 형식 (coco dataset 기준) [top left x position, top left y position, width, height]\n",
    "### class  \n",
    "### 01_ulcer,02_mass,04_lymph,05_bleeding 총 4 개  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cdc779b-db1d-431f-94a8-96223a5bb298",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "\n",
    "\n",
    "import copy\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "\n",
    "from mmdet.apis import set_random_seed\n",
    "\n",
    "from custom_data_pipeline import CUSTOM_LoadImageFromFile\n",
    "\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feee7638-784a-4bcd-bb8d-26bd7cf6e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@DATASETS.register_module()\n",
    "class lesion_ds(CustomDataset):\n",
    "    CLASSES=('01_ulcer','02_mass','04_lymph', '05_bleeding')\n",
    "\n",
    "\n",
    "    def load_annotations(self, ann_file):\n",
    "        \n",
    "        CLASSES_dict = { '01_ulcer' : 0 , '02_mass' : 1, '04_lymph' : 2, '05_bleeding' : 3}\n",
    "        \n",
    "        # load image list from file\n",
    "        image_list = mmcv.list_from_file(self.ann_file)\n",
    "        \n",
    "        data_infos = []\n",
    "        \n",
    "        for idx,img in enumerate(image_list):\n",
    "            json_data = {}\n",
    "            with open(img, \"r\") as json_file:\n",
    "                json_data = json.load(json_file)\n",
    "            \n",
    "            filename = img # json에 annotation + image라서 json 자체를 filename로 주고 LoadImageFromFile을 baseline을 참조하여 custom으로 \n",
    "\n",
    "            height = json_data['imageHeight']\n",
    "            width = json_data['imageWidth']\n",
    "\n",
    "            data_info = dict(filename=filename, width=width, height=height)\n",
    "\n",
    "            gt_bboxes = []\n",
    "            gt_labels = []\n",
    "\n",
    "            for a_idx in range(len(json_data['shapes'])):\n",
    "                gt_labels.append(CLASSES_dict[json_data['shapes'][a_idx]['label']])\n",
    "                \n",
    "                ## 좌표순서 좌상 우상 우하 좌하 \n",
    "                ## mmdetection의 default annotation loader는 'coco_panoptic.py'에 있는데 여기 기준으로 하면 bbox에는 x1,y1,x2,y2가 담겨야함\n",
    "                ## 만약에 이렇게 따로 load를 하지 않을시에는 x,y,w,h 형태로 annotaion을 생성하면 자동으로 x1,y1,x2,y2로 변환해줌 \n",
    "                ori_pos = np.array(json_data['shapes'][a_idx]['points'])\n",
    "                x1, y1, x2, y2 = min(ori_pos[:, 0]), min(ori_pos[:, 1]), max(ori_pos[:, 0]), max(ori_pos[:, 1])\n",
    "                \n",
    "                if x1 == 0 : \n",
    "                    x1 = 1 \n",
    "                if y1 == 0 : \n",
    "                    y1 = 1 \n",
    "                \n",
    "                if x2 == width: \n",
    "                    x2 = x2 - 1 \n",
    "                if y2 == width: \n",
    "                    y2 = y2-1 \n",
    "            \n",
    "                \n",
    "                if x1==x2 or y1==y2:\n",
    "                    print('Grond-truth Bounding Box 이상체크')\n",
    "                    print(filename)\n",
    "                     \n",
    "                \n",
    "                gt_bboxes.append([x1,y1,x2,y2])\n",
    "                \n",
    "\n",
    "            data_anno = dict(\n",
    "                    bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
    "                    labels=np.array(gt_labels, dtype=np.long))\n",
    "\n",
    "\n",
    "            data_info.update(ann=data_anno)\n",
    "            data_infos.append(data_info)\n",
    "            \n",
    "            if idx!=0 and idx%20000==0:\n",
    "                print(str(idx)+'/'+str(len(image_list))+' load annotations END!')\n",
    "            \n",
    "        \n",
    "        \n",
    "        return data_infos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "092012d4-70cf-4a2d-b664-bb1335c50c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 추가수정 기존 받았던 pretrain과 매칭되는 config로 수정 \n",
    "cfg = Config.fromfile('mmdetection/configs/resnest/cascade_rcnn_s101_fpn_syncbn-backbone+head_mstrain-range_1x_coco.py') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccaeb79b-fec0-4f99-8a11-16cc4d5fd0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='CascadeRCNN',\n",
      "    backbone=dict(\n",
      "        type='ResNeSt',\n",
      "        depth=101,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=False,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='open-mmlab://resnest101'),\n",
      "        stem_channels=128,\n",
      "        radix=2,\n",
      "        reduction_factor=4,\n",
      "        avg_down_stride=True),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(\n",
      "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='CascadeRoIHead',\n",
      "        num_stages=3,\n",
      "        stage_loss_weights=[1, 0.5, 0.25],\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                type='Shared4Conv1FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                conv_out_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                norm_cfg=dict(type='BN', requires_grad=True),\n",
      "                roi_feat_size=7,\n",
      "                num_classes=4,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
      "                               loss_weight=1.0)),\n",
      "            dict(\n",
      "                type='Shared4Conv1FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                conv_out_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                norm_cfg=dict(type='BN', requires_grad=True),\n",
      "                roi_feat_size=7,\n",
      "                num_classes=4,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
      "                               loss_weight=1.0)),\n",
      "            dict(\n",
      "                type='Shared4Conv1FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                conv_out_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                norm_cfg=dict(type='BN', requires_grad=True),\n",
      "                roi_feat_size=7,\n",
      "                num_classes=4,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
      "        ]),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=0,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=2000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    min_pos_iou=0.6,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    min_pos_iou=0.7,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False)\n",
      "        ]),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100)))\n",
      "dataset_type = 'lesion_ds'\n",
      "data_root = ''\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='CUSTOM_LoadImageFromFile', to_float32=True),\n",
      "    dict(type='PhotoMetricDistortion'),\n",
      "    dict(\n",
      "        type='LoadAnnotations',\n",
      "        with_bbox=True,\n",
      "        with_mask=False,\n",
      "        poly2mask=False),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=[(576, 576), (600, 600)],\n",
      "        multiscale_mode='range',\n",
      "        keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.675, 116.28, 103.53],\n",
      "        std=[58.395, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='CUSTOM_LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(600, 600),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    samples_per_gpu=4,\n",
      "    workers_per_gpu=2,\n",
      "    train=dict(\n",
      "        filter_empty_gt=False,\n",
      "        pipeline=[\n",
      "            dict(type='CUSTOM_LoadImageFromFile', to_float32=True),\n",
      "            dict(type='PhotoMetricDistortion'),\n",
      "            dict(\n",
      "                type='LoadAnnotations',\n",
      "                with_bbox=True,\n",
      "                with_mask=False,\n",
      "                poly2mask=False),\n",
      "            dict(\n",
      "                type='Resize',\n",
      "                img_scale=[(576, 576), (600, 600)],\n",
      "                multiscale_mode='range',\n",
      "                keep_ratio=True),\n",
      "            dict(type='RandomFlip', flip_ratio=0.5),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='DefaultFormatBundle'),\n",
      "            dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "        ],\n",
      "        ann_file='splits/lesion_train.txt',\n",
      "        type='lesion_ds'),\n",
      "    val=dict(\n",
      "        pipeline=[\n",
      "            dict(type='CUSTOM_LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(600, 600),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        ann_file='splits/lesion_val.txt',\n",
      "        type='lesion_ds'),\n",
      "    test=dict(\n",
      "        pipeline=[\n",
      "            dict(type='CUSTOM_LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(600, 600),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        type='lesion_ds'))\n",
      "evaluation = dict(interval=1, metric='mAP')\n",
      "optimizer = dict(\n",
      "    type='AdamW', lr=0.0001, betas=(0.9, 0.999), weight_decay=0.05)\n",
      "optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=500, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = 'lesion_checkpoints_ver2/epoch_12.pth'\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "norm_cfg = dict(type='BN', requires_grad=True)\n",
      "work_dir = 'lesion_checkpoints_ver2_2'\n",
      "seed = 0\n",
      "gpu_ids = [0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg.dataset_type  = 'lesion_ds'\n",
    "cfg.data_root = ''\n",
    "\n",
    "## coco datset으로 pretrain된 weight load \n",
    "# 최초학습시 pretrain path \n",
    "cfg.load_from = 'pretrain/cascade_rcnn_s101_fpn_syncbn-backbone+head_mstrain-range_1x_coco.pth'\n",
    "# 12epoch까지 갔는데 아직 validation 성능이 계속오르기만해서 weight load이후 추가 학습진행 \n",
    "# cfg.load_from = 'lesion_checkpoints_ver2/epoch_12.pth'\n",
    "# 추가학습이후 경향이 좋아지지 않아서 학습멈춤.. 타 모델 학습시켜서 ENSEMBLE에 사용해볼 예정 \n",
    "cfg.work_dir = 'lesion_checkpoints_ver2'\n",
    "\n",
    "cfg.evaluation.metric = 'mAP'\n",
    "\n",
    "#sync bn하면 single gpu라 error 발생 \n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "\n",
    "#class 4개로 \n",
    "cfg.model.roi_head.bbox_head[0].num_classes=4\n",
    "\n",
    "cfg.model.roi_head.bbox_head[1].num_classes=4\n",
    "\n",
    "cfg.model.roi_head.bbox_head[2].num_classes=4\n",
    "\n",
    "#데이터 pipeline은 config 참조 \n",
    "cfg.img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "\n",
    "## 원본이 576 / 576\n",
    "## 이미지의 높이 너비 비율은 동일하게 두는 것으로..\n",
    "## flip 외에도   PhotoMetricDistortion  augmentation 추가..\n",
    "## auto augment는 컴퓨터 자원 문제로 배제함..\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='CUSTOM_LoadImageFromFile',to_float32=True),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(\n",
    "        type='LoadAnnotations',\n",
    "        with_bbox=True,\n",
    "        with_mask=False,\n",
    "        poly2mask=False),\n",
    "    dict(\n",
    "        type='Resize',\n",
    "        img_scale=[(576, 576), (600, 600)],\n",
    "        multiscale_mode='range',\n",
    "        keep_ratio=True),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "    dict(type='Pad', size_divisor=32),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels']),\n",
    "]\n",
    "\n",
    "## 실제 test시에는 Test Time Augmentation 적용하는 것으로 \n",
    "cfg.test_pipeline = [\n",
    "    dict(type='CUSTOM_LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(600, 600),\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='Pad', size_divisor=32),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img'])\n",
    "        ])\n",
    "]\n",
    "\n",
    "# batch size 3060에 맞게 set (기존 pretrain시에는  batch 32 사용했다고 되어있음)\n",
    "cfg.data = dict(\n",
    "    samples_per_gpu=4,\n",
    "    workers_per_gpu=2,\n",
    "    train=dict(filter_empty_gt=False, pipeline=cfg.train_pipeline,ann_file='splits/lesion_train.txt'),\n",
    "    val=dict(pipeline=cfg.test_pipeline,ann_file='splits/lesion_val.txt'),\n",
    "    test=dict(pipeline=cfg.test_pipeline))\n",
    "\n",
    "\n",
    "cfg.data.train.type = cfg.dataset_type\n",
    "cfg.data.val.type = cfg.dataset_type\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "\n",
    "# optimizer AdamW로 변경이후 learning rate도 낮게 줌\n",
    "cfg.optimizer = dict(type='AdamW', lr=0.0001, betas=(0.9, 0.999), weight_decay=0.05)\n",
    "cfg.optimizer_config = dict(grad_clip=dict(max_norm=35, norm_type=2))\n",
    "\n",
    "# 처음학습시에는 쓰고 12epoch에서 더 학습시킬때는 안씀..\n",
    "# cfg.lr_config = dict(\n",
    "#     policy='step',\n",
    "#     warmup='linear',\n",
    "#     warmup_iters=2500,\n",
    "#     warmup_ratio=0.000125,\n",
    "#     step=[8, 11])\n",
    "\n",
    "\n",
    "#2480\n",
    "cfg.log_config.interval = 500 #iteration 단위\n",
    "cfg.evaluation.interval = 1 #epoch 단위\n",
    "cfg.checkpoint_config.interval = 1 #epoch 단위\n",
    "\n",
    "# seed set\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = [0]\n",
    "\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3682dcb6-9665-4b55-bab8-68c438329ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7054c81c-d7fd-4722-9778-ae3d5f88c17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:60: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/59491 load annotations END!\n",
      "40000/59491 load annotations END!\n"
     ]
    }
   ],
   "source": [
    "# Build dataset\n",
    "datasets = [build_dataset(cfg.data.train)]\n",
    "\n",
    "# Build the detector\n",
    "model = build_detector(\n",
    "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16617445-931a-4a3a-803f-883af17783e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datasets)\n",
    "\n",
    "# Create work_dir\n",
    "mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "\n",
    "train_detector(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd246d0-6fa2-4266-b3b1-c302ee8bda02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
