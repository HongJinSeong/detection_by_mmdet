{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a90950-bd80-41eb-8f20-fec74578bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector, show_result_pyplot\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "\n",
    "\n",
    "import copy\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "\n",
    "from mmdet.apis import set_random_seed\n",
    "\n",
    "from mmdet.core.post_processing import bbox_nms\n",
    "\n",
    "\n",
    "import base64\n",
    "\n",
    "import glob as _glob\n",
    "import os\n",
    "\n",
    "import json\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "import pandas as pd \n",
    "\n",
    "from mmcv.visualization import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d99a0f96-ed65-438c-a29a-77bfbfd9dea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def glob(dir, pats, recursive=False):  # faster than match, python3 only\n",
    "    pats = pats if isinstance(pats, (list, tuple)) else [pats]\n",
    "    matches = []\n",
    "    for pat in pats:\n",
    "        matches += _glob.glob(os.path.join(dir, pat), recursive=recursive)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30e8ed22-5cc9-42bb-bcc4-c61a73b83d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 추가수정 기존 받았던 pretrain과 매칭되는 config로 수정 \n",
    "cfg = Config.fromfile('mmdetection/configs/resnest/cascade_rcnn_s101_fpn_syncbn-backbone+head_mstrain-range_1x_coco.py') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61768152-f124-4cf5-b1fb-a1cf7a236052",
   "metadata": {},
   "outputs": [],
   "source": [
    "@DATASETS.register_module()\n",
    "class lesion_ds(CustomDataset):\n",
    "    CLASSES=('01_ulcer','02_mass','04_lymph', '05_bleeding')\n",
    "\n",
    "\n",
    "    def load_annotations(self, ann_file):\n",
    "        \n",
    "        CLASSES_dict = { '01_ulcer' : 0 , '02_mass' : 1, '04_lymph' : 2, '05_bleeding' : 3}\n",
    "        \n",
    "        # load image list from file\n",
    "        image_list = mmcv.list_from_file(self.ann_file)\n",
    "        \n",
    "        data_infos = []\n",
    "        \n",
    "        for idx,img in enumerate(image_list):\n",
    "            json_data = {}\n",
    "            with open(img, \"r\") as json_file:\n",
    "                json_data = json.load(json_file)\n",
    "            \n",
    "            filename = img # json에 annotation + image라서 json 자체를 filename로 주고 LoadImageFromFile을 baseline을 참조하여 custom으로 \n",
    "\n",
    "            height = json_data['imageHeight']\n",
    "            width = json_data['imageWidth']\n",
    "\n",
    "            data_info = dict(filename=filename, width=width, height=height)\n",
    "\n",
    "            gt_bboxes = []\n",
    "            gt_labels = []\n",
    "\n",
    "            for a_idx in range(len(json_data['shapes'])):\n",
    "                gt_labels.append(CLASSES_dict[json_data['shapes'][a_idx]['label']])\n",
    "                \n",
    "                ## 좌표순서 좌상 우상 우하 좌하 \n",
    "                ## mmdetection의 default annotation loader는 'coco_panoptic.py'에 있는데 여기 기준으로 하면 bbox에는 x1,y1,x2,y2가 담겨야함\n",
    "                ## 만약에 이렇게 따로 annotation을 load를 하지 않을시에는 x,y,w,h 형태로 annotaion을 생성하면 자동으로 x1,y1,x2,y2로 변환해줌 \n",
    "                ori_pos = np.array(json_data['shapes'][a_idx]['points'])\n",
    "                x1, y1, x2, y2 = min(ori_pos[:, 0]), min(ori_pos[:, 1]), max(ori_pos[:, 0]), max(ori_pos[:, 1])\n",
    "                \n",
    "                if x1 == 0 : \n",
    "                    x1 = 1 \n",
    "                if y1 == 0 : \n",
    "                    y1 = 1 \n",
    "                \n",
    "                if x2 == width: \n",
    "                    x2 = x2 - 1 \n",
    "                if y2 == width: \n",
    "                    y2 = y2 - 1 \n",
    "            \n",
    "                \n",
    "                if x1==x2 or y1==y2:\n",
    "                    print('Grond-truth Bounding Box 이상체크')\n",
    "                    print(filename)\n",
    "                     \n",
    "                \n",
    "                gt_bboxes.append([x1,y1,x2,y2])\n",
    "                \n",
    "\n",
    "            data_anno = dict(\n",
    "                    bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
    "                    labels=np.array(gt_labels, dtype=np.long))\n",
    "\n",
    "\n",
    "            data_info.update(ann=data_anno)\n",
    "            data_infos.append(data_info)\n",
    "            \n",
    "            if idx!=0 and idx%20000==0:\n",
    "                print(str(idx)+'/'+str(len(image_list))+' load annotations END!')\n",
    "            \n",
    "        \n",
    "        \n",
    "        return data_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ce22367-2ea3-4d74-9702-6c7678d8581d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "model = dict(\n",
      "    type='CascadeRCNN',\n",
      "    backbone=dict(\n",
      "        type='ResNeSt',\n",
      "        depth=101,\n",
      "        num_stages=4,\n",
      "        out_indices=(0, 1, 2, 3),\n",
      "        frozen_stages=1,\n",
      "        norm_cfg=dict(type='BN', requires_grad=True),\n",
      "        norm_eval=False,\n",
      "        style='pytorch',\n",
      "        init_cfg=dict(type='Pretrained', checkpoint='open-mmlab://resnest101'),\n",
      "        stem_channels=128,\n",
      "        radix=2,\n",
      "        reduction_factor=4,\n",
      "        avg_down_stride=True),\n",
      "    neck=dict(\n",
      "        type='FPN',\n",
      "        in_channels=[256, 512, 1024, 2048],\n",
      "        out_channels=256,\n",
      "        num_outs=5),\n",
      "    rpn_head=dict(\n",
      "        type='RPNHead',\n",
      "        in_channels=256,\n",
      "        feat_channels=256,\n",
      "        anchor_generator=dict(\n",
      "            type='AnchorGenerator',\n",
      "            scales=[8],\n",
      "            ratios=[0.5, 1.0, 2.0],\n",
      "            strides=[4, 8, 16, 32, 64]),\n",
      "        bbox_coder=dict(\n",
      "            type='DeltaXYWHBBoxCoder',\n",
      "            target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
      "        loss_cls=dict(\n",
      "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
      "        loss_bbox=dict(\n",
      "            type='SmoothL1Loss', beta=0.1111111111111111, loss_weight=1.0)),\n",
      "    roi_head=dict(\n",
      "        type='CascadeRoIHead',\n",
      "        num_stages=3,\n",
      "        stage_loss_weights=[1, 0.5, 0.25],\n",
      "        bbox_roi_extractor=dict(\n",
      "            type='SingleRoIExtractor',\n",
      "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
      "            out_channels=256,\n",
      "            featmap_strides=[4, 8, 16, 32]),\n",
      "        bbox_head=[\n",
      "            dict(\n",
      "                type='Shared4Conv1FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                conv_out_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                norm_cfg=dict(type='BN', requires_grad=True),\n",
      "                roi_feat_size=7,\n",
      "                num_classes=4,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
      "                               loss_weight=1.0)),\n",
      "            dict(\n",
      "                type='Shared4Conv1FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                conv_out_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                norm_cfg=dict(type='BN', requires_grad=True),\n",
      "                roi_feat_size=7,\n",
      "                num_classes=4,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.05, 0.05, 0.1, 0.1]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0,\n",
      "                               loss_weight=1.0)),\n",
      "            dict(\n",
      "                type='Shared4Conv1FCBBoxHead',\n",
      "                in_channels=256,\n",
      "                conv_out_channels=256,\n",
      "                fc_out_channels=1024,\n",
      "                norm_cfg=dict(type='BN', requires_grad=True),\n",
      "                roi_feat_size=7,\n",
      "                num_classes=4,\n",
      "                bbox_coder=dict(\n",
      "                    type='DeltaXYWHBBoxCoder',\n",
      "                    target_means=[0.0, 0.0, 0.0, 0.0],\n",
      "                    target_stds=[0.033, 0.033, 0.067, 0.067]),\n",
      "                reg_class_agnostic=True,\n",
      "                loss_cls=dict(\n",
      "                    type='CrossEntropyLoss',\n",
      "                    use_sigmoid=False,\n",
      "                    loss_weight=1.0),\n",
      "                loss_bbox=dict(type='SmoothL1Loss', beta=1.0, loss_weight=1.0))\n",
      "        ]),\n",
      "    train_cfg=dict(\n",
      "        rpn=dict(\n",
      "            assigner=dict(\n",
      "                type='MaxIoUAssigner',\n",
      "                pos_iou_thr=0.7,\n",
      "                neg_iou_thr=0.3,\n",
      "                min_pos_iou=0.3,\n",
      "                match_low_quality=True,\n",
      "                ignore_iof_thr=-1),\n",
      "            sampler=dict(\n",
      "                type='RandomSampler',\n",
      "                num=256,\n",
      "                pos_fraction=0.5,\n",
      "                neg_pos_ub=-1,\n",
      "                add_gt_as_proposals=False),\n",
      "            allowed_border=0,\n",
      "            pos_weight=-1,\n",
      "            debug=False),\n",
      "        rpn_proposal=dict(\n",
      "            nms_pre=2000,\n",
      "            max_per_img=2000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=[\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.5,\n",
      "                    neg_iou_thr=0.5,\n",
      "                    min_pos_iou=0.5,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.6,\n",
      "                    neg_iou_thr=0.6,\n",
      "                    min_pos_iou=0.6,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False),\n",
      "            dict(\n",
      "                assigner=dict(\n",
      "                    type='MaxIoUAssigner',\n",
      "                    pos_iou_thr=0.7,\n",
      "                    neg_iou_thr=0.7,\n",
      "                    min_pos_iou=0.7,\n",
      "                    match_low_quality=False,\n",
      "                    ignore_iof_thr=-1),\n",
      "                sampler=dict(\n",
      "                    type='RandomSampler',\n",
      "                    num=512,\n",
      "                    pos_fraction=0.25,\n",
      "                    neg_pos_ub=-1,\n",
      "                    add_gt_as_proposals=True),\n",
      "                pos_weight=-1,\n",
      "                debug=False)\n",
      "        ]),\n",
      "    test_cfg=dict(\n",
      "        rpn=dict(\n",
      "            nms_pre=1000,\n",
      "            max_per_img=1000,\n",
      "            nms=dict(type='nms', iou_threshold=0.7),\n",
      "            min_bbox_size=0),\n",
      "        rcnn=dict(\n",
      "            score_thr=0.05,\n",
      "            nms=dict(type='nms', iou_threshold=0.5),\n",
      "            max_per_img=100)))\n",
      "dataset_type = 'CocoDataset'\n",
      "data_root = 'data/coco/'\n",
      "img_norm_cfg = dict(\n",
      "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
      "train_pipeline = [\n",
      "    dict(type='LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='LoadAnnotations',\n",
      "        with_bbox=True,\n",
      "        with_mask=False,\n",
      "        poly2mask=False),\n",
      "    dict(\n",
      "        type='Resize',\n",
      "        img_scale=[(1333, 640), (1333, 800)],\n",
      "        multiscale_mode='range',\n",
      "        keep_ratio=True),\n",
      "    dict(type='RandomFlip', flip_ratio=0.5),\n",
      "    dict(\n",
      "        type='Normalize',\n",
      "        mean=[123.68, 116.779, 103.939],\n",
      "        std=[58.393, 57.12, 57.375],\n",
      "        to_rgb=True),\n",
      "    dict(type='Pad', size_divisor=32),\n",
      "    dict(type='DefaultFormatBundle'),\n",
      "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])\n",
      "]\n",
      "test_pipeline = [\n",
      "    dict(type='CUSTOM_LoadImageFromFile'),\n",
      "    dict(\n",
      "        type='MultiScaleFlipAug',\n",
      "        img_scale=(600, 600),\n",
      "        flip=False,\n",
      "        transforms=[\n",
      "            dict(type='Resize', keep_ratio=True),\n",
      "            dict(type='RandomFlip'),\n",
      "            dict(\n",
      "                type='Normalize',\n",
      "                mean=[123.675, 116.28, 103.53],\n",
      "                std=[58.395, 57.12, 57.375],\n",
      "                to_rgb=True),\n",
      "            dict(type='Pad', size_divisor=32),\n",
      "            dict(type='ImageToTensor', keys=['img']),\n",
      "            dict(type='Collect', keys=['img'])\n",
      "        ])\n",
      "]\n",
      "data = dict(\n",
      "    test=dict(\n",
      "        pipeline=[\n",
      "            dict(type='CUSTOM_LoadImageFromFile'),\n",
      "            dict(\n",
      "                type='MultiScaleFlipAug',\n",
      "                img_scale=(600, 600),\n",
      "                flip=False,\n",
      "                transforms=[\n",
      "                    dict(type='Resize', keep_ratio=True),\n",
      "                    dict(type='RandomFlip'),\n",
      "                    dict(\n",
      "                        type='Normalize',\n",
      "                        mean=[123.675, 116.28, 103.53],\n",
      "                        std=[58.395, 57.12, 57.375],\n",
      "                        to_rgb=True),\n",
      "                    dict(type='Pad', size_divisor=32),\n",
      "                    dict(type='ImageToTensor', keys=['img']),\n",
      "                    dict(type='Collect', keys=['img'])\n",
      "                ])\n",
      "        ],\n",
      "        type='CocoDataset'))\n",
      "evaluation = dict(interval=1, metric='bbox')\n",
      "optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)\n",
      "optimizer_config = dict(grad_clip=None)\n",
      "lr_config = dict(\n",
      "    policy='step',\n",
      "    warmup='linear',\n",
      "    warmup_iters=500,\n",
      "    warmup_ratio=0.001,\n",
      "    step=[8, 11])\n",
      "runner = dict(type='EpochBasedRunner', max_epochs=12)\n",
      "checkpoint_config = dict(interval=1)\n",
      "log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])\n",
      "custom_hooks = [dict(type='NumClassCheckHook')]\n",
      "dist_params = dict(backend='nccl')\n",
      "log_level = 'INFO'\n",
      "load_from = None\n",
      "resume_from = None\n",
      "workflow = [('train', 1)]\n",
      "norm_cfg = dict(type='BN', requires_grad=True)\n",
      "seed = 0\n",
      "gpu_ids = [0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sync bn하면 single gpu라 error 발생 \n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True)\n",
    "\n",
    "#class 4개로 \n",
    "cfg.model.roi_head.bbox_head[0].num_classes=4\n",
    "\n",
    "cfg.model.roi_head.bbox_head[1].num_classes=4\n",
    "\n",
    "cfg.model.roi_head.bbox_head[2].num_classes=4\n",
    "\n",
    "#데이터 pipeline은 config 참조 \n",
    "cfg.img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "\n",
    "## 실제 test시에는 Test Time Augmentation 적용하는 것으로 \n",
    "cfg.test_pipeline = [\n",
    "    dict(type='CUSTOM_LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(600, 600),\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='Pad', size_divisor=32),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img'])\n",
    "        ])\n",
    "]\n",
    "cfg.data = dict(\n",
    "    test=dict(pipeline=cfg.test_pipeline))\n",
    "\n",
    "\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "\n",
    "\n",
    "# seed set\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = [0]\n",
    "\n",
    "print(f'Config:\\n{cfg.pretty_text}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1a4179d-fd1c-4e0f-8cd8-0d258d58070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load checkpoint from local path: lesion_checkpoints_ver2/epoch_10.pth\n"
     ]
    }
   ],
   "source": [
    "# Build the detector\n",
    "#model = init_detector(config, checkpoint, device='cuda:0')\n",
    "checkpoint='lesion_checkpoints_ver2/epoch_10.pth'\n",
    "# model = init_detector(cfg,checkpoint, device='cpu')\n",
    "model = init_detector(cfg, checkpoint, device='cuda:0')\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40868f3c-5274-4e00-a915-c73a11c50cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ls=glob('lesion_DB/test','*')\n",
    "test_ls.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41835ddb-deae-46bc-90fd-833b33629180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 end!\n",
      "100 end!\n",
      "200 end!\n",
      "300 end!\n",
      "400 end!\n",
      "500 end!\n",
      "600 end!\n",
      "700 end!\n",
      "800 end!\n",
      "900 end!\n",
      "1000 end!\n",
      "1100 end!\n",
      "1200 end!\n",
      "1300 end!\n",
      "1400 end!\n",
      "1500 end!\n",
      "1600 end!\n",
      "1700 end!\n",
      "1800 end!\n",
      "1900 end!\n",
      "2000 end!\n",
      "2100 end!\n",
      "2200 end!\n",
      "2300 end!\n",
      "2400 end!\n",
      "2500 end!\n",
      "2600 end!\n",
      "2700 end!\n",
      "2800 end!\n",
      "2900 end!\n",
      "3000 end!\n",
      "3100 end!\n",
      "3200 end!\n",
      "3300 end!\n",
      "3400 end!\n",
      "3500 end!\n",
      "3600 end!\n",
      "3700 end!\n",
      "3800 end!\n",
      "3900 end!\n",
      "4000 end!\n",
      "4100 end!\n",
      "4200 end!\n",
      "4300 end!\n",
      "4400 end!\n",
      "4500 end!\n",
      "4600 end!\n",
      "4700 end!\n",
      "4800 end!\n",
      "4900 end!\n",
      "5000 end!\n",
      "5100 end!\n",
      "5200 end!\n",
      "5300 end!\n",
      "5400 end!\n",
      "5500 end!\n",
      "5600 end!\n",
      "5700 end!\n",
      "5800 end!\n",
      "5900 end!\n",
      "6000 end!\n",
      "6100 end!\n",
      "6200 end!\n",
      "6300 end!\n",
      "6400 end!\n",
      "6500 end!\n",
      "6600 end!\n",
      "6700 end!\n",
      "6800 end!\n",
      "6900 end!\n",
      "7000 end!\n",
      "7100 end!\n",
      "7200 end!\n",
      "7300 end!\n",
      "7400 end!\n",
      "7500 end!\n",
      "7600 end!\n",
      "7700 end!\n",
      "7800 end!\n",
      "7900 end!\n",
      "8000 end!\n",
      "8100 end!\n",
      "8200 end!\n",
      "8300 end!\n",
      "8400 end!\n",
      "8500 end!\n",
      "8600 end!\n",
      "8700 end!\n",
      "8800 end!\n",
      "8900 end!\n",
      "9000 end!\n",
      "9100 end!\n",
      "9200 end!\n",
      "9300 end!\n",
      "9400 end!\n",
      "9500 end!\n",
      "9600 end!\n",
      "9700 end!\n",
      "9800 end!\n",
      "9900 end!\n",
      "10000 end!\n",
      "10100 end!\n",
      "10200 end!\n",
      "10300 end!\n",
      "10400 end!\n",
      "10500 end!\n",
      "10600 end!\n",
      "10700 end!\n",
      "10800 end!\n",
      "10900 end!\n",
      "11000 end!\n",
      "11100 end!\n",
      "11200 end!\n",
      "11300 end!\n",
      "11400 end!\n",
      "11500 end!\n",
      "11600 end!\n",
      "11700 end!\n",
      "11800 end!\n",
      "11900 end!\n",
      "12000 end!\n",
      "12100 end!\n",
      "12200 end!\n",
      "12300 end!\n",
      "12400 end!\n",
      "12500 end!\n",
      "12600 end!\n",
      "12700 end!\n",
      "12800 end!\n",
      "12900 end!\n",
      "13000 end!\n",
      "13100 end!\n",
      "13200 end!\n",
      "13300 end!\n",
      "13400 end!\n",
      "13500 end!\n",
      "13600 end!\n",
      "13700 end!\n",
      "13800 end!\n",
      "13900 end!\n",
      "14000 end!\n",
      "14100 end!\n",
      "14200 end!\n",
      "14300 end!\n",
      "14400 end!\n",
      "14500 end!\n",
      "14600 end!\n",
      "14700 end!\n",
      "14800 end!\n",
      "14900 end!\n",
      "15000 end!\n",
      "15100 end!\n",
      "15200 end!\n",
      "15300 end!\n",
      "15400 end!\n",
      "15500 end!\n",
      "15600 end!\n",
      "15700 end!\n",
      "15800 end!\n",
      "15900 end!\n",
      "16000 end!\n",
      "16100 end!\n",
      "16200 end!\n",
      "16300 end!\n",
      "16400 end!\n",
      "16500 end!\n",
      "16600 end!\n",
      "16700 end!\n",
      "16800 end!\n",
      "16900 end!\n",
      "17000 end!\n",
      "17100 end!\n",
      "17200 end!\n",
      "17300 end!\n",
      "17400 end!\n",
      "17500 end!\n",
      "17600 end!\n",
      "17700 end!\n",
      "17800 end!\n",
      "17900 end!\n",
      "18000 end!\n",
      "18100 end!\n",
      "18200 end!\n",
      "18300 end!\n",
      "18400 end!\n",
      "18500 end!\n",
      "18600 end!\n",
      "18700 end!\n",
      "18800 end!\n",
      "18900 end!\n",
      "19000 end!\n",
      "19100 end!\n",
      "19200 end!\n",
      "19300 end!\n",
      "19400 end!\n",
      "19500 end!\n",
      "19600 end!\n",
      "19700 end!\n",
      "19800 end!\n",
      "19900 end!\n",
      "20000 end!\n",
      "20100 end!\n",
      "20200 end!\n",
      "20300 end!\n",
      "20400 end!\n",
      "20500 end!\n",
      "20600 end!\n",
      "20700 end!\n",
      "20800 end!\n"
     ]
    }
   ],
   "source": [
    "CLASSES_dict = { 0 : '01_ulcer' , 1 : '02_mass' , 2 : '04_lymph' , 3 : '05_bleeding' }\n",
    "CLASS_NAME=['01_ulcer','02_mass','04_lymph','05_bleeding']\n",
    "\n",
    "results_for_csv = {\n",
    "    'file_name':[], 'class_id':[], 'confidence':[], 'point1_x':[], 'point1_y':[],\n",
    "    'point2_x':[], 'point2_y':[], 'point3_x':[], 'point3_y':[], 'point4_x':[], 'point4_y':[]\n",
    "}\n",
    "\n",
    "\n",
    "### 기존 NMS사용시 단순 Threshoold 기준으로 output 간추려 낸것보다 성능이 낮아짐 \n",
    "### https://github.com/BichenWuUCB/squeezeDet 소스 사용 \n",
    "def iou(box1, box2):\n",
    "  '''Compute the Intersection-Over-Union of two given boxes.\n",
    "  Args:\n",
    "    box1: array of 4 elements [cx, cy, width, height].\n",
    "    box2: same as above\n",
    "  Returns:\n",
    "    iou: a float number in range [0, 1]. iou of the two boxes.\n",
    "  '''\n",
    "\n",
    "  lr = min(box1[0]+0.5*box1[2], box2[0]+0.5*box2[2]) - \\\n",
    "      max(box1[0]-0.5*box1[2], box2[0]-0.5*box2[2])\n",
    "  if lr > 0:\n",
    "    tb = min(box1[1]+0.5*box1[3], box2[1]+0.5*box2[3]) - \\\n",
    "        max(box1[1]-0.5*box1[3], box2[1]-0.5*box2[3])\n",
    "    if tb > 0:\n",
    "      intersection = tb*lr\n",
    "      union = box1[2]*box1[3]+box2[2]*box2[3]-intersection\n",
    "\n",
    "      return intersection/union\n",
    "\n",
    "  return 0\n",
    "\n",
    "def batch_iou(boxes, box):\n",
    "  '''Compute the Intersection-Over-Union of a batch of boxes with another\n",
    "  box.\n",
    "  Args:\n",
    "    box1: 2D array of [cx, cy, width, height].\n",
    "    box2: a single array of [cx, cy, width, height]\n",
    "  Returns:\n",
    "    ious: array of a float number in range [0, 1].\n",
    "  '''\n",
    "  lr = np.maximum(\n",
    "      np.minimum(boxes[:,0]+0.5*boxes[:,2], box[0]+0.5*box[2]) - \\\n",
    "      np.maximum(boxes[:,0]-0.5*boxes[:,2], box[0]-0.5*box[2]),\n",
    "      0\n",
    "  )\n",
    "  tb = np.maximum(\n",
    "      np.minimum(boxes[:,1]+0.5*boxes[:,3], box[1]+0.5*box[3]) - \\\n",
    "      np.maximum(boxes[:,1]-0.5*boxes[:,3], box[1]-0.5*box[3]),\n",
    "      0\n",
    "  )\n",
    "  inter = lr*tb\n",
    "  union = boxes[:,2]*boxes[:,3] + box[2]*box[3] - inter\n",
    "  return inter/union\n",
    "\n",
    "def nms(boxes, probs, threshold):\n",
    "  '''Non-Maximum supression.\n",
    "  Args:\n",
    "    boxes: array of [cx, cy, w, h] (center format)\n",
    "    probs: array of probabilities\n",
    "    threshold: two boxes are considered overlapping if their IOU is largher than\n",
    "        this threshold\n",
    "    form: 'center' or 'diagonal'\n",
    "  Returns:\n",
    "    keep: array of True or False.\n",
    "  '''\n",
    " \n",
    "  order = probs.argsort()[::-1]\n",
    "  keep = [True]*len(order)\n",
    " \n",
    "  for i in range(len(order)-1):\n",
    "    ovps = batch_iou(boxes[order[i+1:]], boxes[order[i]])\n",
    "    for j, ov in enumerate(ovps):\n",
    "      if ov > threshold:\n",
    "        keep[order[j+i+1]] = False\n",
    "  return keep\n",
    "\n",
    "### https://github.com/BichenWuUCB/squeezeDet 소스 사용 \n",
    "\n",
    "for t_idx, filename in enumerate(test_ls):\n",
    "    with open(filename, \"r\") as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "\n",
    "    img_bytes = base64.b64decode(json_data['imageData'])\n",
    "\n",
    "    img = mmcv.imfrombytes(img_bytes, flag='color',backend='pillow')\n",
    "\n",
    "    img = img.astype(np.float32)\n",
    "    \n",
    "    \n",
    "    ## output shape x1, y1, x2, y2 , confidence score\n",
    "    results = inference_detector(model, img)\n",
    "    \n",
    "    ## 단순 threshold 값 기준으로 하면 겹치는 box가 너무많이 생겨서 발생하는 문제 해결이 안되기 때문에 NMS로 겹쳐지는 박스의 경우 제거 해주는 것이 필요해보임 \n",
    "    for cls_idx, result in enumerate(results):\n",
    "        if result.shape[0]!=0:\n",
    "            out_nms = nms(result[:,0:4],result[:,4],0.4)\n",
    "            save_target = result[out_nms]\n",
    "            for pos_idx, pos, in enumerate(save_target):\n",
    "                results_for_csv['file_name'].append(filename.split('/')[-1])\n",
    "                results_for_csv['class_id'].append(cls_idx+1)\n",
    "                results_for_csv['confidence'].append(pos[4])\n",
    "                results_for_csv['point1_x'].append(pos[0])\n",
    "                results_for_csv['point1_y'].append(pos[1])\n",
    "                results_for_csv['point2_x'].append(pos[2])\n",
    "                results_for_csv['point2_y'].append(pos[1])\n",
    "                results_for_csv['point3_x'].append(pos[2])\n",
    "                results_for_csv['point3_y'].append(pos[3])\n",
    "                results_for_csv['point4_x'].append(pos[0])\n",
    "                results_for_csv['point4_y'].append(pos[3])\n",
    "    \n",
    "    \n",
    "    ## 적정 threshold 값 모르겠으니 일단 test output 싹다 저장해서 이미지 봐도 어느정도 score가 좋을지 잘모르겠음..\n",
    "    # model.show_result(img,results,score_thr=0.0,out_file='infer_show_checkpoints10/'+filename.split('/')[-1][:-5]+'.png')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    ## result list로 0 1 2 3  ==> 4개 class \n",
    "    ## class id 는 1부터 시작하니까 +1 해줌 \n",
    "    #  0.407    0.89\n",
    "    # for cls_idx, result in enumerate(results):\n",
    "    #     ## output이 0이 아니고 \n",
    "    #     if result.shape[0]!=0:\n",
    "    #         # print(result)\n",
    "    #         thre_val = result[np.where(result[:,4]>=0.407)]\n",
    "    #         if thre_val.shape[0]!=0:\n",
    "    #             for pos_idx, pos, in enumerate(thre_val):\n",
    "    #                 results_for_csv['file_name'].append(filename.split('/')[-1])\n",
    "    #                 results_for_csv['class_id'].append(cls_idx+1)\n",
    "    #                 results_for_csv['confidence'].append(pos[4])\n",
    "    #                 results_for_csv['point1_x'].append(pos[0])\n",
    "    #                 results_for_csv['point1_y'].append(pos[1])\n",
    "    #                 results_for_csv['point2_x'].append(pos[2])\n",
    "    #                 results_for_csv['point2_y'].append(pos[1])\n",
    "    #                 results_for_csv['point3_x'].append(pos[2])\n",
    "    #                 results_for_csv['point3_y'].append(pos[3])\n",
    "    #                 results_for_csv['point4_x'].append(pos[0])\n",
    "    #                 results_for_csv['point4_y'].append(pos[3])\n",
    "            #confidence score가 0.5보다 클 때\n",
    "            # if result[np.where(result[:,4]>0.5)].shape[0]!=0:\n",
    "            #         print('11')\n",
    "    if t_idx%100==0:\n",
    "        print(str(t_idx) + ' end!')\n",
    "     \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5dd1699-276d-4180-b417-3b5ee1e0bbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(results_for_csv)\n",
    "submission.to_csv('HJS_VER1_NMS_TH_IOU0.4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ae988e-937f-4b0a-ad02-1ab9c49075df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
